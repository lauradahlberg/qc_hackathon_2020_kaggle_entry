{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final submission to Queen City's Hackathon 2020 - Kaggle track\n",
    "---\n",
    "in this one we add a voting classifier for best models. We used three regressor:\n",
    "1. KNeighborsRegressor\n",
    "1. RandomForestRegressor\n",
    "1. MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, RandomForestClassifier)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## per competition's judging criteria: the models will be evaulated\n",
    "## ... using a weighted MSE\n",
    "## wmse = the weighted mean squared error. \n",
    "def wmse(actual, pred, weight):\n",
    "    return sum((actual - pred) * (actual - pred) * weight) / sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## testing wmse function with arbitrary numbers\n",
    "wmse(np.array([0,1]), np.array([1,1]), np.array([2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/raw/.ipynb_checkpoints',\n",
       " 'data/raw/data description.csv',\n",
       " 'data/raw/example_code.py',\n",
       " 'data/raw/testing.csv',\n",
       " 'data/raw/training.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## gloval variables ##\n",
    "## ---------------- ##\n",
    "PROJ = Path(r\".\")\n",
    "DATA = PROJ/'data'\n",
    "RAW = DATA/'raw'\n",
    "data_files_list = list(RAW.iterdir())\n",
    "[str(f) for f in data_files_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Reading the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45 entries, 0 to 44\n",
      "Columns: 495 entries, Area_2015 to Transit_Ridership_Total_2013\n",
      "dtypes: float64(352), int64(143)\n",
      "memory usage: 174.4 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = pd.read_csv(RAW/'testing.csv', index_col=0)\n",
    "test_data.info()\n",
    "## As we can see test_data doesn't \n",
    "## have the 'target' column, which is the one we'll predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 416 entries, 0 to 415\n",
      "Columns: 496 entries, Area_2015 to target\n",
      "dtypes: float64(353), int64(143)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(RAW/'training.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating the weights for the wmse function\n",
    "## the competition estipulated that the errors will be weighted by\n",
    "## ...the column 'Population _2018'\n",
    "weights = df['Population _2018']\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area_2015                         0\n",
       "Area_2013                         0\n",
       "Population_Density_2018           0\n",
       "Population _2018                  0\n",
       "Population_Density_2017           0\n",
       "                               ... \n",
       "Transit_Ridership_2014          107\n",
       "Transit_Ridership_Total_2014    107\n",
       "Transit_Ridership_2013          106\n",
       "Transit_Ridership_Total_2013    106\n",
       "target                            0\n",
       "Length: 496, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking to see if there are any nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we include 'weights_train, weights_test' to the splitting when we have to give WMSE results\n",
    "### first we drop the label column 'target' from X(with which we'll train our data)\n",
    "X = df.drop('target', axis=1).copy()\n",
    "y = df['target'].copy()\n",
    "X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(X, y, weights, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312, 495), (104, 495), (312,), (104,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trans_Xtest.shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(104, 495)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('knn',\n",
       "                             KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                                 metric='minkowski',\n",
       "                                                 metric_params=None,\n",
       "                                                 n_jobs=None, n_neighbors=6,\n",
       "                                                 p=2, weights='uniform')),\n",
       "                            ('rf',\n",
       "                             RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_im...\n",
       "                                          beta_2=0.999, early_stopping=False,\n",
       "                                          epsilon=1e-08,\n",
       "                                          hidden_layer_sizes=(100,),\n",
       "                                          learning_rate='constant',\n",
       "                                          learning_rate_init=0.001,\n",
       "                                          max_fun=15000, max_iter=200,\n",
       "                                          momentum=0.9, n_iter_no_change=10,\n",
       "                                          nesterovs_momentum=True, power_t=0.5,\n",
       "                                          random_state=42, shuffle=True,\n",
       "                                          solver='lbfgs', tol=0.0001,\n",
       "                                          validation_fraction=0.1,\n",
       "                                          verbose=False, warm_start=False))],\n",
       "                n_jobs=None, weights=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = Pipeline([('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "                       ('scaler', StandardScaler())])\n",
    "\n",
    "## calculating the 'imputer' and 'scaler' values for the X_train set\n",
    "## QUESTION: where else is this used? \n",
    "trans.fit(X_train)\n",
    "\n",
    "## replacing the values with the newly calculated values, and \n",
    "## ...returning a new dataset.\n",
    "trans_Xtrain = trans.transform(X_train)\n",
    "trans_Xtest = trans.transform(X_test)\n",
    "\n",
    "display('trans_Xtest.shape:', trans_Xtest.shape) ## these are the same numbers as X_test.shape -- shouldn't it be different?\n",
    "\n",
    "## applying transform to the test_data dataset\n",
    "trans_test = trans.transform(test_data)\n",
    "\n",
    "models3 = VotingRegressor([('knn', KNeighborsRegressor(n_neighbors=6)),\n",
    "                          ('rf', RandomForestRegressor(random_state=42)), \n",
    "                          ('mlp', MLPRegressor(solver='lbfgs', \n",
    "                                              alpha=1e-5, \n",
    "                                              hidden_layer_sizes=(100,), \n",
    "                                              max_iter=200, \n",
    "                                              random_state=42,\n",
    "                                              n_iter_no_change=10))])\n",
    "models3.fit(trans_Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.19\n",
      "1.2738969793223929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37505134694783393"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making predictions from training set\n",
    "predicts = models3.predict(trans_Xtest)\n",
    "print(\"Test Score: {:.2f}\".format(models3.score(trans_Xtest, y_test)))\n",
    "print(metrics.mean_squared_error(y_test,predicts))\n",
    "wmse(y_test, predicts, weights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making predictions for test_data set\n",
    "predicts_test_data = models3.predict(trans_test)\n",
    "\n",
    "## checking that the test data set has 45 rows.\n",
    "predicts_test_data.shape\n",
    "\n",
    "## in this case, we don't know how we did because we don't have the data. \n",
    "## only the judges know the answer, right?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
